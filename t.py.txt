import numpy as np
import scipy.stats
from scipy.optimize import brentq
from multiprocessing import Pool

class PT_variN:
    """
    df: dataframe with at least one column named 'gcdu_id' and each row represent a year
    rho: asset correlation
    theta: intertemporal correlation
    num_simulation: number of simulations
    N_defaults: cumulative number of observed default
    confidence_level: confidence level for pluto-tasche approach
    """
    def __init__(self, df, rho, theta):
        self.N = df['gcdu_id'].tolist()
        self.T = len(self.N)
        self.rho = rho
        self.theta = theta
        self.Nmax = max(self.N)
        self.rng = np.random.default_rng()
        self.mu = np.zeros(self.T)
        self.sigma = self._calculate_sigma()
    
    def _calculate_sigma(self):
        sigma = np.zeros((self.T, self.T))
        for i in range(self.T):
            for j in range(self.T):
                sigma[i][j] = np.power(self.theta, abs(i - j))
        return sigma
    
    def sum_of_defaults(self, PD):
        idiosyncratic_full_box = self.rng.normal(size=(self.Nmax, self.T))
        systematic_box = np.array([self.rng.multivariate_normal(self.mu, self.sigma, 1)[0]] * self.Nmax)
    
        for j, k in enumerate(self.N):
            idiosyncratic_full_box[k:, j] = np.nan
            systematic_box[k:, j] = np.nan
    
        asset_return = np.sqrt(self.rho) * systematic_box + np.sqrt(1 - self.rho) * idiosyncratic_full_box
        asset_return[np.isnan(asset_return)] = 99999
        defaults = asset_return < scipy.stats.norm.ppf(PD)
        return defaults.sum()
    
    def simulation(self, PD, num_simulation):
        return np.array([self.sum_of_defaults(PD) for _ in range(num_simulation)])
    
    def obj_func(self, PD, num_simulation, N_defaults, confidence_level):
        alpha = 1 - np.mean(self.simulation(PD, num_simulation) <= N_defaults)
        return alpha - confidence_level
    
    def calculate_pd(self, PD, num_simulation, N_defaults, confidence_level):
        return brentq(self.obj_func, a=1e-7, b=1 - 1e-7, args=(PD, num_simulation, N_defaults, confidence_level))

def calculate_pd_wrapper(args):
    return PT_variN(*args).calculate_pd(500, n_defaults, 0.50), PT_variN(*args).calculate_pd(500, n_defaults, 0.85)

# Initialize empty lists to store results
pd_data = [(lradr_data[lradr_data.cohort_month == i], 0.18, 0.7) for i in range(1, 13)]

# Use multiprocessing Pool for parallel processing
with Pool() as pool:
    results = pool.map(calculate_pd_wrapper, pd_data)

# Extract results
pd_best_estimate, pd_conservative = zip(*results)

# Compute final estimates
pd_best_estimate_final = np.mean(pd_best_estimate)
pd_conservative_final = np.mean(pd_conservative) + np.std(pd_conservative)
